:imagesdir: ../../../static/img
== Kafka

=== 事件日志、发布者和消费者

kafka是用来处理数据流的系统。从概念上讲，我们可以认为Kafa包括三个基本组件：

* 一个事件日志（Event Log），消息发布到它这里
* 发布者（Publisher），将消息发布到事件日志
* 消费者（Consumer），消费（也就是使用）事件日志中的消息

image::mq_kafka.dio.svg[]

kafka由消费者来决定何时读取消息（kafka采用了拉取而非推送模式）。每条消息都有一个偏移量，每个消费者都跟踪（或提交）其最近消费消息的偏移量。这样，消费者就可以通过这条消息的偏移量请求下一条消息。

=== 分区和分区建

主题被进一步细分为多个分区（partition）。分区使消息可以被并行消费。Kafka允许通过严格 *分区键* （ *partition key*）来确定性的将消息分配给各个分区。分区键是一段数据（通常是消息本身的某些属性，例如ID），其上会应用一个算法以确定分区

image::mq_kafka_topic.dio.svg[]

使用分区键，使我们能够确保与给定ID关联的每条消息都会发不到单个分区上。还需要注意点是，可以将一个消费者的多个实例部署为一个消费者组。Kafka将确保给定分区中的任何消息将始终由组中的同一消费者实例读取。



== 如何防止数据丢失

生成者：同步发送消息，且消息配置为-1或all，leader分区和所有follwer都写到磁盘里。

异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生成者一直处于阻塞状态。

生成者：手动提交，即读取到消息后，确认消息消费完毕，才手动提交offset。但是要避免逻辑处理时间过长，导致连接超时，会让消息重复消费。

故kafka一定要配置上消息重试的机制，并且重试的时间间隔一定公钥长一些，默认1秒钟并不符合生成环境（网络中断时间有可能超过1秒）。

* *log.flush.interval.messages* 和 *log.flush.interval.ms* 来配置flush间隔

* 消息大小

== 至少一次语义（At least once semantics）

== 至多一次语义（At most once semantics）

== 精确一次语义（Exactly once semantics）

* 通过跨分区原子写入实现（Transactions：Atomic writes across multiple partitions）
* 批量提交id保证消息去重

== DelayQueue

> 基于时间轮+DelayQueue





== 特点

在Kafka中，采用消息追加的方式来写入每个消息，每个消息读写时都会利用Page Cache的预读和后写特性，同时partition中都使用顺序读写，以此来提高I/O性能。
虽然Kafka能够根据偏移量查找到具体的某个消息，但是查找过程是顺序查找，因此如果数据很大的话，查找效率就很低。所以Kafka中采用了分段和索引的方式来解决查找效率问题。Kafka把一个patition大文件又分成了多个小文件段，每个小文件段以偏移量命名，通过多个小文件段，不仅可以使用二分搜索法很快定位消息，同时也容易定期清除或删除已经消费完的文件，减少磁盘占用。为了进一步提高查找效率，Kafka为每个分段后的数据建立了索引文件，并通过索引文件稀疏存储来降低元数据占用大小。